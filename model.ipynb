{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, default_collate\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='Training', transform=None):\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.transform = transform\n",
    "        self.labels = {'정상': 0, '균핵병': 1, '노균병': 2}\n",
    "        self.data = []\n",
    "        self._load_dataset()\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        for label_name, label in self.labels.items():\n",
    "            path = os.path.join(self.root_dir, '원천데이터', '05.상추', f'05.상추_{label}.{label_name}')\n",
    "            images = os.listdir(path)\n",
    "            for image in images:\n",
    "                self.data.append((os.path.join(path, image), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader에서 None 타입 데이터를 걸러내기 위한 함수\n",
    "def my_collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x[0] is not None, batch))\n",
    "    return default_collate(batch)\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 및 DataLoader 인스턴스 생성\n",
    "root_dir = '/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/realdata'\n",
    "train_dataset = CustomDataset(root_dir=root_dir, split='Training', transform=transform)\n",
    "val_dataset = CustomDataset(root_dir=root_dir, split='Validation', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=my_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=my_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Epoch: 1/10, Phase: train, Loss: 0.7718769501756739, ACC: 0.7051851851851851\n",
      "Epoch: 1/10, Phase: val, Loss: 0.5412274956703186, ACC: 0.8333333333333334\n",
      "Model saved\n",
      "================\n",
      "Epoch: 2/10, Phase: train, Loss: 0.2516471983326806, ACC: 0.9362962962962963\n",
      "Epoch: 2/10, Phase: val, Loss: 0.3869178838200039, ACC: 0.8555555555555555\n",
      "Model saved\n",
      "================\n",
      "Epoch: 3/10, Phase: train, Loss: 0.07735049975139123, ACC: 0.9896296296296296\n",
      "Epoch: 3/10, Phase: val, Loss: 0.4657071338759528, ACC: 0.8444444444444444\n",
      "================\n",
      "Epoch: 4/10, Phase: train, Loss: 0.0499773649043507, ACC: 0.9940740740740741\n",
      "Epoch: 4/10, Phase: val, Loss: 0.5377604391839769, ACC: 0.8444444444444444\n",
      "================\n",
      "Epoch: 5/10, Phase: train, Loss: 0.038128319460277754, ACC: 0.9881481481481481\n",
      "Epoch: 5/10, Phase: val, Loss: 0.3816556341118283, ACC: 0.8333333333333334\n",
      "Model saved\n",
      "================\n",
      "Epoch: 6/10, Phase: train, Loss: 0.04473652953350985, ACC: 0.9881481481481481\n",
      "Epoch: 6/10, Phase: val, Loss: 0.4366233189900716, ACC: 0.8444444444444444\n",
      "================\n",
      "Epoch: 7/10, Phase: train, Loss: 0.04204448838166341, ACC: 0.9866666666666667\n",
      "Epoch: 7/10, Phase: val, Loss: 0.7165447460280524, ACC: 0.8111111111111111\n",
      "================\n",
      "Epoch: 8/10, Phase: train, Loss: 0.03736141303071269, ACC: 0.9925925925925926\n",
      "Epoch: 8/10, Phase: val, Loss: 0.7197219636705187, ACC: 0.8222222222222222\n",
      "================\n",
      "Epoch: 9/10, Phase: train, Loss: 0.014713495648293584, ACC: 0.9985185185185185\n",
      "Epoch: 9/10, Phase: val, Loss: 0.5904201431406869, ACC: 0.8777777777777778\n",
      "================\n",
      "Epoch: 10/10, Phase: train, Loss: 0.02560188163899713, ACC: 0.9940740740740741\n",
      "Epoch: 10/10, Phase: val, Loss: 0.6087223437097338, ACC: 0.8555555555555555\n"
     ]
    }
   ],
   "source": [
    "# 모델, 손실 함수, 최적화 알고리즘 설정\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)  # 전이학습 - 가중치 그대로 사용\n",
    "num_ftrs = model.fc.in_features  # 모델의 마지막 fully connected층의 입력 특성 수 가져옴\n",
    "model.fc = nn.Linear(num_ftrs, 3)  # 원래 모델의 마지막 fc레이어를 새로운 레이어로 대체 - num_ftrs개의 입력 특성을 받아 3개의 출력을 가정\n",
    "criterion = nn.CrossEntropyLoss()  # 다중 클래스 분류에 적합한 손실함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 훈련 및 검증 루프\n",
    "num_epochs = 10\n",
    "best_cost = 1e+10\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"================\")\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # 모델을 학습 모드로 설정\n",
    "        else:\n",
    "            model.eval()   # 모델을 평가 모드로 설정\n",
    "\n",
    "        running_loss = 0.0\n",
    "        corrects = 0\n",
    "        sample_size = 0\n",
    "\n",
    "        # 데이터 로더 설정\n",
    "        dataloader = train_loader if phase == 'train' else val_loader\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "            sample_size += images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / sample_size\n",
    "        epoch_acc = corrects.double() / sample_size\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Phase: {phase}, Loss: {epoch_loss}, ACC: {epoch_acc}\")\n",
    "\n",
    "        # 모델 저장\n",
    "        if phase == 'val' and epoch_loss < best_cost:\n",
    "            print(\"Model saved\")\n",
    "            best_cost = epoch_loss\n",
    "            torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지를 불러오고 전처리하기 위한 transform 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((254, 254)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # 이미지 불러오기 및 변환\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    # 모델로 예측\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # 예측된 라벨 반환\n",
    "    return preds.item()\n",
    "\n",
    "# 모델 가중치 불러오기 (앞서 저장한 'model.pt')\n",
    "model.load_state_dict(torch.load('model.pt', map_location=device))\n",
    "\n",
    "# 예측할 이미지의 경로 설정\n",
    "image_path = '/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/KakaoTalk_Photo_2024-05-14-02-06-39.jpeg'\n",
    "\n",
    "# 이미지에 대한 예측 라벨 출력\n",
    "predicted_label = predict_image(image_path)\n",
    "print(f'Predicted label: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.35215914249420166, Batch Accuracy: 0.875\n",
      "Batch Loss: 0.5211045742034912, Batch Accuracy: 0.75\n",
      "Batch Loss: 0.12497228384017944, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.2852169871330261, Batch Accuracy: 0.8125\n",
      "Batch Loss: 1.9388319253921509, Batch Accuracy: 0.4375\n",
      "Batch Loss: 1.3500956296920776, Batch Accuracy: 0.4\n",
      "Total Test Loss: 0.7228612767325507, Total Test Accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋과 데이터로더 설정\n",
    "test_dataset = CustomDataset(root_dir=root_dir, split='Test', transform=transform)  # 테스트 데이터셋 추가\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=my_collate_fn)  # 테스트 DataLoader 추가\n",
    "\n",
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "model.to(device)\n",
    "\n",
    "# 테스트 성능 평가\n",
    "running_loss = 0.0\n",
    "corrects = 0\n",
    "sample_size = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # forward\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "    batch_loss = loss.item() * images.size(0)\n",
    "    batch_corrects = torch.sum(preds == labels.data)\n",
    "    \n",
    "    running_loss += batch_loss\n",
    "    corrects += batch_corrects\n",
    "    sample_size += images.size(0)\n",
    "    \n",
    "    # 현재 배치에 대한 손실과 정확도 출력\n",
    "    print(f\"Batch Loss: {batch_loss / images.size(0)}, Batch Accuracy: {batch_corrects.double() / images.size(0)}\")\n",
    "\n",
    "# 전체 테스트 데이터셋에 대한 손실과 정확도 계산\n",
    "test_loss = running_loss / sample_size\n",
    "test_acc = corrects.double() / sample_size\n",
    "\n",
    "print(f\"Total Test Loss: {test_loss}, Total Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "드롬아웃 정규화 과정 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms, models\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, default_collate\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='Training', transform=None):\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.transform = transform\n",
    "        self.labels = {'정상': 0, '균핵병': 1, '노균병': 2}\n",
    "        self.data = []\n",
    "        self._load_dataset()\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        for label_name, label in self.labels.items():\n",
    "            path = os.path.join(self.root_dir, '원천데이터', '05.상추', f'05.상추_{label}.{label_name}')\n",
    "            images = os.listdir(path)\n",
    "            for image in images:\n",
    "                self.data.append((os.path.join(path, image), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x[0] is not None, batch))\n",
    "    return default_collate(batch)\n",
    "\n",
    "transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "root_dir = '/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/realdata'\n",
    "train_dataset = CustomDataset(root_dir=root_dir, split='Training', transform=transform)\n",
    "val_dataset = CustomDataset(root_dir=root_dir, split='Validation', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=my_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=my_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Epoch: 1/10, Phase: train, Loss: 0.8883889710461652, ACC: 0.6296296296296297\n",
      "Epoch: 1/10, Phase: val, Loss: 0.7205109119415283, ACC: 0.7555555555555555\n",
      "Model saved\n",
      "================\n",
      "Epoch: 2/10, Phase: train, Loss: 0.3323624184396532, ACC: 0.9155555555555556\n",
      "Epoch: 2/10, Phase: val, Loss: 0.36825948026445177, ACC: 0.8555555555555555\n",
      "Model saved\n",
      "================\n",
      "Epoch: 3/10, Phase: train, Loss: 0.11591981335922524, ACC: 0.9777777777777777\n",
      "Epoch: 3/10, Phase: val, Loss: 0.5498534917831421, ACC: 0.8111111111111111\n",
      "================\n",
      "Epoch: 4/10, Phase: train, Loss: 0.07139786466404244, ACC: 0.9837037037037037\n",
      "Epoch: 4/10, Phase: val, Loss: 0.3372687406010098, ACC: 0.8777777777777778\n",
      "Model saved\n",
      "================\n",
      "Epoch: 5/10, Phase: train, Loss: 0.05348755577096233, ACC: 0.9866666666666667\n",
      "Epoch: 5/10, Phase: val, Loss: 0.5368229495154486, ACC: 0.8111111111111111\n",
      "================\n",
      "Epoch: 6/10, Phase: train, Loss: 0.07361215866274304, ACC: 0.9837037037037037\n",
      "Epoch: 6/10, Phase: val, Loss: 0.4027541094356113, ACC: 0.8444444444444444\n",
      "================\n",
      "Epoch: 7/10, Phase: train, Loss: 0.03883763454026646, ACC: 0.9881481481481481\n",
      "Epoch: 7/10, Phase: val, Loss: 0.3720300833384196, ACC: 0.8555555555555555\n",
      "================\n",
      "Epoch: 8/10, Phase: train, Loss: 0.034067606451334775, ACC: 0.9940740740740741\n",
      "Epoch: 8/10, Phase: val, Loss: 0.5024236943986681, ACC: 0.8222222222222222\n",
      "================\n",
      "Epoch: 9/10, Phase: train, Loss: 0.04270579782349092, ACC: 0.9866666666666667\n",
      "Epoch: 9/10, Phase: val, Loss: 0.5845829248428345, ACC: 0.8111111111111111\n",
      "================\n",
      "Epoch: 10/10, Phase: train, Loss: 0.042750233422826835, ACC: 0.9925925925925926\n",
      "Epoch: 10/10, Phase: val, Loss: 0.48557780583699545, ACC: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# 모델 수정: 마지막 fc 레이어에 드롭아웃 추가\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),  # 50% 드롭아웃 추가\n",
    "    nn.Linear(num_ftrs, 3)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "best_cost = 1e+10\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"================\")\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        corrects = 0\n",
    "        sample_size = 0\n",
    "\n",
    "        dataloader = train_loader if phase == 'train' else val_loader\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "            sample_size += images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / sample_size\n",
    "        epoch_acc = corrects.double() / sample_size\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Phase: {phase}, Loss: {epoch_loss}, ACC: {epoch_acc}\")\n",
    "\n",
    "        if phase == 'val' and epoch_loss < best_cost:\n",
    "            print(\"Model saved\")\n",
    "            best_cost = epoch_loss\n",
    "            torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Epoch: 1/10, Phase: train, Loss: 0.8441790437698364, ACC: 0.6474074074074074\n",
      "Epoch: 1/10, Phase: val, Loss: 0.6914378960927328, ACC: 0.8\n",
      "Model saved\n",
      "================\n",
      "Epoch: 2/10, Phase: train, Loss: 0.35340622588440224, ACC: 0.9288888888888889\n",
      "Epoch: 2/10, Phase: val, Loss: 0.40390792422824434, ACC: 0.8444444444444444\n",
      "Model saved\n",
      "================\n",
      "Epoch: 3/10, Phase: train, Loss: 0.1398392449926447, ACC: 0.9688888888888889\n",
      "Epoch: 3/10, Phase: val, Loss: 0.46304677195019195, ACC: 0.8333333333333334\n",
      "================\n",
      "Epoch: 4/10, Phase: train, Loss: 0.06579520942988219, ACC: 0.9896296296296296\n",
      "Epoch: 4/10, Phase: val, Loss: 0.5430264419979519, ACC: 0.8333333333333334\n",
      "================\n",
      "Epoch: 5/10, Phase: train, Loss: 0.04419552864851775, ACC: 0.9925925925925926\n",
      "Epoch: 5/10, Phase: val, Loss: 0.6648262951109144, ACC: 0.8\n",
      "================\n",
      "Epoch: 6/10, Phase: train, Loss: 0.045713702594792405, ACC: 0.9911111111111112\n",
      "Epoch: 6/10, Phase: val, Loss: 0.5314710425006018, ACC: 0.8222222222222222\n",
      "================\n",
      "Epoch: 7/10, Phase: train, Loss: 0.04523011863231659, ACC: 0.9911111111111112\n",
      "Epoch: 7/10, Phase: val, Loss: 0.5311632898118761, ACC: 0.8333333333333334\n",
      "================\n",
      "Epoch: 8/10, Phase: train, Loss: 0.020114905221594703, ACC: 0.9985185185185185\n",
      "Epoch: 8/10, Phase: val, Loss: 0.5953895833757189, ACC: 0.7888888888888889\n",
      "================\n",
      "Epoch: 9/10, Phase: train, Loss: 0.0440597040840873, ACC: 0.9940740740740741\n",
      "Epoch: 9/10, Phase: val, Loss: 0.4970418055852254, ACC: 0.7777777777777778\n",
      "================\n",
      "Epoch: 10/10, Phase: train, Loss: 0.03332916949082304, ACC: 0.9911111111111112\n",
      "Epoch: 10/10, Phase: val, Loss: 0.4923218250274658, ACC: 0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "#평가모드 수정코드 \n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# 모델 수정: 마지막 fc 레이어에 드롭아웃 추가\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),  # 50% 드롭아웃 추가\n",
    "    nn.Linear(num_ftrs, 3)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "best_cost = 1e+10\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"================\")\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        corrects = 0\n",
    "        sample_size = 0\n",
    "\n",
    "        dataloader = train_loader if phase == 'train' else val_loader\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "            sample_size += images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / sample_size\n",
    "        epoch_acc = corrects.double() / sample_size\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Phase: {phase}, Loss: {epoch_loss}, ACC: {epoch_acc}\")\n",
    "\n",
    "        if phase == 'val' and epoch_loss < best_cost:\n",
    "            print(\"Model saved\")\n",
    "            best_cost = epoch_loss\n",
    "            torch.save(model.state_dict(), 'model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지를 불러오고 전처리하기 위한 transform 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((254, 254)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # 이미지 불러오기 및 변환\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    # 모델로 예측\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # 예측된 라벨 반환\n",
    "    return preds.item()\n",
    "\n",
    "# 모델 가중치 불러오기 (앞서 저장한 'model.pt')\n",
    "model.load_state_dict(torch.load('model.pt', map_location=device))\n",
    "\n",
    "# 예측할 이미지의 경로 설정\n",
    "image_path = '/Users/leeyeonju/Desktop/smart-plant-ai/이연주 서명.png'\n",
    "\n",
    "# 이미지에 대한 예측 라벨 출력\n",
    "predicted_label = predict_image(image_path)\n",
    "print(f'Predicted label: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 모델 구조를 재정의\n",
    "def initialize_model():\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),  # 50% 드롭아웃 추가\n",
    "        nn.Linear(num_ftrs, 3)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 이미지를 불러오고 전처리하기 위한 transform 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((254, 254)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 모델 로드\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = initialize_model()  # 모델 구조 초기화\n",
    "model.load_state_dict(torch.load('model.pt', map_location=device))  # 학습된 가중치 로드\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # 이미지 불러오기 및 변환\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    # 모델로 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # 예측된 라벨 반환\n",
    "    return preds.item()\n",
    "\n",
    "# 예시 사용\n",
    "# 예측 결과 = predict_image('path_to_your_image.jpg')\n",
    "# print(\"Predicted label:\", 예측 결과)\n",
    "\n",
    "\n",
    "res = predict_image('/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/realdata/Training/원천데이터/05.상추/05.상추_2.노균병/V006_77_1_10_05_03_12_1_0149e_20201209_14.jpeg')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path):\n",
    "    # 모델 구조를 재정의\n",
    "    def initialize_model():\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),  # 50% 드롭아웃 추가\n",
    "        nn.Linear(num_ftrs, 3)\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    # 모델 로드\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = initialize_model()  # 모델 구조 초기화\n",
    "    model.load_state_dict(torch.load('model.pt', map_location=device))  # 학습된 가중치 로드\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((254, 254)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image) #이미지 전처리 \n",
    "    image = image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    # 모델로 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # 예측된 라벨 반환\n",
    "    return preds.item()\n",
    "\n",
    "\n",
    "\n",
    "res = predict_image('/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/스크린샷 2024-05-17 오후 9.49.14.png')\n",
    "print(type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.6018965840339661, Batch Accuracy: 0.75\n",
      "Batch Loss: 0.4976913332939148, Batch Accuracy: 0.8125\n",
      "Batch Loss: 0.16763010621070862, Batch Accuracy: 0.9375\n",
      "Batch Loss: 0.28867360949516296, Batch Accuracy: 0.875\n",
      "Batch Loss: 0.8924418687820435, Batch Accuracy: 0.625\n",
      "Batch Loss: 0.8347737193107605, Batch Accuracy: 0.4\n",
      "Total Test Loss: 0.5280119246906705, Total Test Accuracy: 0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋과 데이터로더 설정\n",
    "test_dataset = CustomDataset(root_dir=root_dir, split='Test', transform=transform)  # 테스트 데이터셋 추가\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=my_collate_fn)  # 테스트 DataLoader 추가\n",
    "\n",
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "model.to(device)\n",
    "\n",
    "# 테스트 성능 평가\n",
    "running_loss = 0.0\n",
    "corrects = 0\n",
    "sample_size = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # forward\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "    batch_loss = loss.item() * images.size(0)\n",
    "    batch_corrects = torch.sum(preds == labels.data)\n",
    "    \n",
    "    running_loss += batch_loss\n",
    "    corrects += batch_corrects\n",
    "    sample_size += images.size(0)\n",
    "    \n",
    "    # 현재 배치에 대한 손실과 정확도 출력\n",
    "    print(f\"Batch Loss: {batch_loss / images.size(0)}, Batch Accuracy: {batch_corrects.double() / images.size(0)}\")\n",
    "\n",
    "# 전체 테스트 데이터셋에 대한 손실과 정확도 계산\n",
    "test_loss = running_loss / sample_size\n",
    "test_acc = corrects.double() / sample_size\n",
    "\n",
    "print(f\"Total Test Loss: {test_loss}, Total Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*서버에서 이미지를 받아 모델에서 출력하는 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지를 불러오고 전처리하기 위한 transform 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((254, 254)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 모델 로드\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.load('model.pt', map_location=device)\n",
    "model.eval()\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # 이미지 불러오기 및 변환\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    # 모델로 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # 예측된 라벨 반환\n",
    "    return preds.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
