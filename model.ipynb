{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from torch.utils.data.dataloader import default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomDataset 클래스 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, mode='Training', transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        data_folder = mode  # 'Training', 'Validation', 또는 'Test'\n",
    "        data_path = os.path.join(root_dir, data_folder)\n",
    "        self._load_data(data_path)\n",
    "\n",
    "    def _load_data(self, data_path):\n",
    "        image_folder_path = os.path.join(data_path, \"원천데이터\", \"05.상추\")\n",
    "        label_folder_path = os.path.join(data_path, \"라벨링데이터\", \"05.상추\")\n",
    "\n",
    "        image_folders = os.listdir(image_folder_path)\n",
    "\n",
    "        for image_folder in image_folders:\n",
    "            image_path = os.path.join(image_folder_path, image_folder)\n",
    "            label_path = os.path.join(label_folder_path, image_folder)\n",
    "\n",
    "            for image_filename in os.listdir(image_path):\n",
    "                image_file_path = os.path.join(image_path, image_filename)\n",
    "                label_file_path = os.path.join(label_path, image_filename.replace('.jpeg', '.json'))\n",
    "\n",
    "                if os.path.exists(label_file_path):\n",
    "                    with open(label_file_path, 'r') as f:\n",
    "                        label_info = json.load(f)\n",
    "                        disease = label_info['annotations']['disease']\n",
    "                        if disease == 9: #균핵병\n",
    "                            label = 1\n",
    "                        elif disease == 10: #노균병\n",
    "                            label = 2\n",
    "                        else:  #정상\n",
    "                            label = 0\n",
    "                else: #라벨 정보가 없으면 정상으로 처리\n",
    "                    label = 0\n",
    "\n",
    "                self.images.append(image_file_path)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        except (IOError, UnidentifiedImageError) as e:\n",
    "            print(f\"Warning: Could not read image {image_path}. Skipping. Error: {e}\")\n",
    "            return None, None\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader에서 None 타입 데이터를 걸러내기 위한 함수\n",
    "def my_collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x[0] is not None, batch))\n",
    "    return default_collate(batch)\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 및 DataLoader 인스턴스 생성\n",
    "root_dir = '/Volumes/T7/상추 질병 진단/realdata'\n",
    "train_dataset = CustomDataset(root_dir=root_dir, mode='Training', transform=transform)\n",
    "val_dataset = CustomDataset(root_dir=root_dir, mode='Validation', transform=transform)\n",
    "test_dataset = CustomDataset(root_dir=root_dir, mode='Test', transform=transform)  # 테스트 데이터셋 추가\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=my_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=my_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=my_collate_fn)  # 테스트 DataLoader 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.26185990289546723\n",
      "Epoch 2/10, Loss: 0.010090648662298918\n",
      "Epoch 3/10, Loss: 0.004057515293446391\n",
      "Epoch 4/10, Loss: 0.002347494405152839\n",
      "Epoch 5/10, Loss: 0.0014592068375434814\n",
      "Epoch 6/10, Loss: 0.0011028347301383524\n",
      "Epoch 7/10, Loss: 0.0008445631741102092\n",
      "Epoch 8/10, Loss: 0.0006179280415296468\n",
      "Epoch 9/10, Loss: 0.0005145735028849612\n",
      "Epoch 10/10, Loss: 0.00043456342753542715\n"
     ]
    }
   ],
   "source": [
    "# 모델, 손실 함수, 최적화 알고리즘 설정\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 훈련 루프\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # 검증 루프 #print(f'Validation Accuracy: {accuracy}%')\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb 셀 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m label_counts\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Training 데이터셋에 대한 라벨별 데이터 수 출력\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m label_counts \u001b[39m=\u001b[39m count_labels(train_dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m label, count \u001b[39min\u001b[39;00m label_counts\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mcount\u001b[39m}\u001b[39;00m\u001b[39m개\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb 셀 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcount_labels\u001b[39m(dataset):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     label_counts \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39m정상\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m균핵병\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m노균병\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _, label \u001b[39min\u001b[39;00m dataset:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mif\u001b[39;00m label \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             label_counts[\u001b[39m'\u001b[39m\u001b[39m정상\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32m/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb 셀 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(image_path)\u001b[39m.\u001b[39mconvert(\u001b[39m'\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, UnidentifiedImageError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/model.ipynb#X15sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWarning: Could not read image \u001b[39m\u001b[39m{\u001b[39;00mimage_path\u001b[39m}\u001b[39;00m\u001b[39m. Skipping. Error: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:93\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     90\u001b[0m         _log_api_usage_once(\u001b[39mself\u001b[39m)\n\u001b[1;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms \u001b[39m=\u001b[39m transforms\n\u001b[0;32m---> 93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m     95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 라벨별 데이터 수를 계산하는 함수\n",
    "def count_labels(dataset):\n",
    "    label_counts = {'정상': 0, '균핵병': 1, '노균병': 2}\n",
    "    for _, label in dataset:\n",
    "        if label == 0:\n",
    "            label_counts['정상'] += 1\n",
    "        elif label == 1:\n",
    "            label_counts['균핵병'] += 1\n",
    "        elif label == 2:\n",
    "            label_counts['노균병'] += 1\n",
    "    return label_counts\n",
    "\n",
    "# Training 데이터셋에 대한 라벨별 데이터 수 출력\n",
    "label_counts = count_labels(train_dataset)\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}개\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수정 후 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상: 225개\n",
      "균핵병: 226개\n",
      "노균병: 227개\n"
     ]
    }
   ],
   "source": [
    "# 라벨별 데이터 수를 계산하는 함수\n",
    "def count_labels(dataset):\n",
    "    label_counts = {'정상': 0, '균핵병': 1, '노균병': 2}\n",
    "    for _, label in dataset:\n",
    "        if label == 0:\n",
    "            label_counts['정상'] += 1\n",
    "        elif label == 1:\n",
    "            label_counts['균핵병'] += 1\n",
    "        elif label == 2:\n",
    "            label_counts['노균병'] += 1\n",
    "    return label_counts\n",
    "\n",
    "# Training 데이터셋에 대한 라벨별 데이터 수 출력\n",
    "label_counts = count_labels(train_dataset)\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, default_collate\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='Training', transform=None):\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.transform = transform\n",
    "        self.labels = {'정상': 0, '균핵병': 1, '노균병': 2}\n",
    "        self.data = []\n",
    "        self._load_dataset()\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        for label_name, label in self.labels.items():\n",
    "            path = os.path.join(self.root_dir, '원천데이터', '05.상추', f'05.상추_{label}.{label_name}')\n",
    "            images = os.listdir(path)\n",
    "            for image in images:\n",
    "                self.data.append((os.path.join(path, image), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader에서 None 타입 데이터를 걸러내기 위한 함수\n",
    "def my_collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x[0] is not None, batch))\n",
    "    return default_collate(batch)\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 및 DataLoader 인스턴스 생성\n",
    "root_dir = '/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/realdata'\n",
    "train_dataset = CustomDataset(root_dir=root_dir, split='Training', transform=transform)\n",
    "val_dataset = CustomDataset(root_dir=root_dir, split='Validation', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=my_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=my_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Epoch: 1/10, Phase: train, Loss: 0.7718769501756739, ACC: 0.7051851851851851\n",
      "Epoch: 1/10, Phase: val, Loss: 0.5412274956703186, ACC: 0.8333333333333334\n",
      "Model saved\n",
      "================\n",
      "Epoch: 2/10, Phase: train, Loss: 0.2516471983326806, ACC: 0.9362962962962963\n",
      "Epoch: 2/10, Phase: val, Loss: 0.3869178838200039, ACC: 0.8555555555555555\n",
      "Model saved\n",
      "================\n",
      "Epoch: 3/10, Phase: train, Loss: 0.07735049975139123, ACC: 0.9896296296296296\n",
      "Epoch: 3/10, Phase: val, Loss: 0.4657071338759528, ACC: 0.8444444444444444\n",
      "================\n",
      "Epoch: 4/10, Phase: train, Loss: 0.0499773649043507, ACC: 0.9940740740740741\n",
      "Epoch: 4/10, Phase: val, Loss: 0.5377604391839769, ACC: 0.8444444444444444\n",
      "================\n",
      "Epoch: 5/10, Phase: train, Loss: 0.038128319460277754, ACC: 0.9881481481481481\n",
      "Epoch: 5/10, Phase: val, Loss: 0.3816556341118283, ACC: 0.8333333333333334\n",
      "Model saved\n",
      "================\n",
      "Epoch: 6/10, Phase: train, Loss: 0.04473652953350985, ACC: 0.9881481481481481\n",
      "Epoch: 6/10, Phase: val, Loss: 0.4366233189900716, ACC: 0.8444444444444444\n",
      "================\n",
      "Epoch: 7/10, Phase: train, Loss: 0.04204448838166341, ACC: 0.9866666666666667\n",
      "Epoch: 7/10, Phase: val, Loss: 0.7165447460280524, ACC: 0.8111111111111111\n",
      "================\n",
      "Epoch: 8/10, Phase: train, Loss: 0.03736141303071269, ACC: 0.9925925925925926\n",
      "Epoch: 8/10, Phase: val, Loss: 0.7197219636705187, ACC: 0.8222222222222222\n",
      "================\n",
      "Epoch: 9/10, Phase: train, Loss: 0.014713495648293584, ACC: 0.9985185185185185\n",
      "Epoch: 9/10, Phase: val, Loss: 0.5904201431406869, ACC: 0.8777777777777778\n",
      "================\n",
      "Epoch: 10/10, Phase: train, Loss: 0.02560188163899713, ACC: 0.9940740740740741\n",
      "Epoch: 10/10, Phase: val, Loss: 0.6087223437097338, ACC: 0.8555555555555555\n"
     ]
    }
   ],
   "source": [
    "# 모델, 손실 함수, 최적화 알고리즘 설정\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)  # 전이학습 - 가중치 그대로 사용\n",
    "num_ftrs = model.fc.in_features  # 모델의 마지막 fully connected층의 입력 특성 수 가져옴\n",
    "model.fc = nn.Linear(num_ftrs, 3)  # 원래 모델의 마지막 fc레이어를 새로운 레이어로 대체 - num_ftrs개의 입력 특성을 받아 3개의 출력을 가정\n",
    "criterion = nn.CrossEntropyLoss()  # 다중 클래스 분류에 적합한 손실함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 훈련 및 검증 루프\n",
    "num_epochs = 10\n",
    "best_cost = 1e+10\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"================\")\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # 모델을 학습 모드로 설정\n",
    "        else:\n",
    "            model.eval()   # 모델을 평가 모드로 설정\n",
    "\n",
    "        running_loss = 0.0\n",
    "        corrects = 0\n",
    "        sample_size = 0\n",
    "\n",
    "        # 데이터 로더 설정\n",
    "        dataloader = train_loader if phase == 'train' else val_loader\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "            sample_size += images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / sample_size\n",
    "        epoch_acc = corrects.double() / sample_size\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Phase: {phase}, Loss: {epoch_loss}, ACC: {epoch_acc}\")\n",
    "\n",
    "        # 모델 저장\n",
    "        if phase == 'val' and epoch_loss < best_cost:\n",
    "            print(\"Model saved\")\n",
    "            best_cost = epoch_loss\n",
    "            torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지를 불러오고 전처리하기 위한 transform 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((254, 254)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # 이미지 불러오기 및 변환\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    # 모델로 예측\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # 예측된 라벨 반환\n",
    "    return preds.item()\n",
    "\n",
    "# 모델 가중치 불러오기 (앞서 저장한 'model.pt')\n",
    "model.load_state_dict(torch.load('model.pt', map_location=device))\n",
    "\n",
    "# 예측할 이미지의 경로 설정\n",
    "image_path = '/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/KakaoTalk_Photo_2024-05-14-02-06-39.jpeg'\n",
    "\n",
    "# 이미지에 대한 예측 라벨 출력\n",
    "predicted_label = predict_image(image_path)\n",
    "print(f'Predicted label: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 225 samples\n",
      "Class 1: 225 samples\n",
      "Class 2: 225 samples\n",
      "Class 0: 30 samples\n",
      "Class 1: 30 samples\n",
      "Class 2: 30 samples\n"
     ]
    }
   ],
   "source": [
    "#클래스별 샘플의 개수 출력 \n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "# 데이터셋에서 각 클래스(0, 1, 2)의 개수를 세기 위한 함수\n",
    "def count_class_samples(loader):\n",
    "    class_counts = Counter()\n",
    "    for _, labels in loader:\n",
    "        class_counts.update(labels.tolist())\n",
    "    return class_counts\n",
    "\n",
    "# 훈련 데이터셋에서 각 클래스의 개수를 세기\n",
    "train_class_counts = count_class_samples(train_loader)\n",
    "\n",
    "# 클래스별 개수 출력\n",
    "for class_label, count in sorted(train_class_counts.items()):\n",
    "    print(f\"Class {class_label}: {count} samples\")\n",
    "\n",
    "# 검증 데이터셋에서도 같은 방식으로 클래스의 개수를 셀 수 있습니다.\n",
    "val_class_counts = count_class_samples(val_loader)\n",
    "\n",
    "# 클래스별 개수 출력\n",
    "for class_label, count in sorted(val_class_counts.items()):\n",
    "    print(f\"Class {class_label}: {count} samples\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
