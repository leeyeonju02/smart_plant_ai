{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, default_collate\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='Training', transform=None):\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.transform = transform\n",
    "        self.labels = {'정상': 0, '균핵병': 1, '노균병': 2}\n",
    "        self.data = []\n",
    "        self._load_dataset()\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        for label_name, label in self.labels.items():\n",
    "            path = os.path.join(self.root_dir, '원천데이터', '05.상추', f'05.상추_{label}.{label_name}')\n",
    "            images = os.listdir(path)\n",
    "            for image in images:\n",
    "                self.data.append((os.path.join(path, image), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader에서 None 타입 데이터를 걸러내기 위한 함수\n",
    "def my_collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x[0] is not None, batch))\n",
    "    return default_collate(batch)\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 및 DataLoader 인스턴스 생성\n",
    "root_dir = '/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/realdata'\n",
    "train_dataset = CustomDataset(root_dir=root_dir, split='Training', transform=transform)\n",
    "val_dataset = CustomDataset(root_dir=root_dir, split='Validation', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=my_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=my_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Epoch: 1/10, Phase: train, Loss: 0.7718769501756739, ACC: 0.7051851851851851\n",
      "Epoch: 1/10, Phase: val, Loss: 0.5412274956703186, ACC: 0.8333333333333334\n",
      "Model saved\n",
      "================\n",
      "Epoch: 2/10, Phase: train, Loss: 0.2516471983326806, ACC: 0.9362962962962963\n",
      "Epoch: 2/10, Phase: val, Loss: 0.3869178838200039, ACC: 0.8555555555555555\n",
      "Model saved\n",
      "================\n",
      "Epoch: 3/10, Phase: train, Loss: 0.07735049975139123, ACC: 0.9896296296296296\n",
      "Epoch: 3/10, Phase: val, Loss: 0.4657071338759528, ACC: 0.8444444444444444\n",
      "================\n",
      "Epoch: 4/10, Phase: train, Loss: 0.0499773649043507, ACC: 0.9940740740740741\n",
      "Epoch: 4/10, Phase: val, Loss: 0.5377604391839769, ACC: 0.8444444444444444\n",
      "================\n",
      "Epoch: 5/10, Phase: train, Loss: 0.038128319460277754, ACC: 0.9881481481481481\n",
      "Epoch: 5/10, Phase: val, Loss: 0.3816556341118283, ACC: 0.8333333333333334\n",
      "Model saved\n",
      "================\n",
      "Epoch: 6/10, Phase: train, Loss: 0.04473652953350985, ACC: 0.9881481481481481\n",
      "Epoch: 6/10, Phase: val, Loss: 0.4366233189900716, ACC: 0.8444444444444444\n",
      "================\n",
      "Epoch: 7/10, Phase: train, Loss: 0.04204448838166341, ACC: 0.9866666666666667\n",
      "Epoch: 7/10, Phase: val, Loss: 0.7165447460280524, ACC: 0.8111111111111111\n",
      "================\n",
      "Epoch: 8/10, Phase: train, Loss: 0.03736141303071269, ACC: 0.9925925925925926\n",
      "Epoch: 8/10, Phase: val, Loss: 0.7197219636705187, ACC: 0.8222222222222222\n",
      "================\n",
      "Epoch: 9/10, Phase: train, Loss: 0.014713495648293584, ACC: 0.9985185185185185\n",
      "Epoch: 9/10, Phase: val, Loss: 0.5904201431406869, ACC: 0.8777777777777778\n",
      "================\n",
      "Epoch: 10/10, Phase: train, Loss: 0.02560188163899713, ACC: 0.9940740740740741\n",
      "Epoch: 10/10, Phase: val, Loss: 0.6087223437097338, ACC: 0.8555555555555555\n"
     ]
    }
   ],
   "source": [
    "# 모델, 손실 함수, 최적화 알고리즘 설정\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)  # 전이학습 - 가중치 그대로 사용\n",
    "num_ftrs = model.fc.in_features  # 모델의 마지막 fully connected층의 입력 특성 수 가져옴\n",
    "model.fc = nn.Linear(num_ftrs, 3)  # 원래 모델의 마지막 fc레이어를 새로운 레이어로 대체 - num_ftrs개의 입력 특성을 받아 3개의 출력을 가정\n",
    "criterion = nn.CrossEntropyLoss()  # 다중 클래스 분류에 적합한 손실함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 훈련 및 검증 루프\n",
    "num_epochs = 10\n",
    "best_cost = 1e+10\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"================\")\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # 모델을 학습 모드로 설정\n",
    "        else:\n",
    "            model.eval()   # 모델을 평가 모드로 설정\n",
    "\n",
    "        running_loss = 0.0\n",
    "        corrects = 0\n",
    "        sample_size = 0\n",
    "\n",
    "        # 데이터 로더 설정\n",
    "        dataloader = train_loader if phase == 'train' else val_loader\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "            sample_size += images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / sample_size\n",
    "        epoch_acc = corrects.double() / sample_size\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Phase: {phase}, Loss: {epoch_loss}, ACC: {epoch_acc}\")\n",
    "\n",
    "        # 모델 저장\n",
    "        if phase == 'val' and epoch_loss < best_cost:\n",
    "            print(\"Model saved\")\n",
    "            best_cost = epoch_loss\n",
    "            torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지를 불러오고 전처리하기 위한 transform 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((254, 254)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # 이미지 불러오기 및 변환\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    # 모델로 예측\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # 예측된 라벨 반환\n",
    "    return preds.item()\n",
    "\n",
    "# 모델 가중치 불러오기 (앞서 저장한 'model.pt')\n",
    "model.load_state_dict(torch.load('model.pt', map_location=device))\n",
    "\n",
    "# 예측할 이미지의 경로 설정\n",
    "image_path = '/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/KakaoTalk_Photo_2024-05-14-02-06-39.jpeg'\n",
    "\n",
    "# 이미지에 대한 예측 라벨 출력\n",
    "predicted_label = predict_image(image_path)\n",
    "print(f'Predicted label: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.35215914249420166, Batch Accuracy: 0.875\n",
      "Batch Loss: 0.5211045742034912, Batch Accuracy: 0.75\n",
      "Batch Loss: 0.12497228384017944, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.2852169871330261, Batch Accuracy: 0.8125\n",
      "Batch Loss: 1.9388319253921509, Batch Accuracy: 0.4375\n",
      "Batch Loss: 1.3500956296920776, Batch Accuracy: 0.4\n",
      "Total Test Loss: 0.7228612767325507, Total Test Accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋과 데이터로더 설정\n",
    "test_dataset = CustomDataset(root_dir=root_dir, split='Test', transform=transform)  # 테스트 데이터셋 추가\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=my_collate_fn)  # 테스트 DataLoader 추가\n",
    "\n",
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "model.to(device)\n",
    "\n",
    "# 테스트 성능 평가\n",
    "running_loss = 0.0\n",
    "corrects = 0\n",
    "sample_size = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # forward\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "    batch_loss = loss.item() * images.size(0)\n",
    "    batch_corrects = torch.sum(preds == labels.data)\n",
    "    \n",
    "    running_loss += batch_loss\n",
    "    corrects += batch_corrects\n",
    "    sample_size += images.size(0)\n",
    "    \n",
    "    # 현재 배치에 대한 손실과 정확도 출력\n",
    "    print(f\"Batch Loss: {batch_loss / images.size(0)}, Batch Accuracy: {batch_corrects.double() / images.size(0)}\")\n",
    "\n",
    "# 전체 테스트 데이터셋에 대한 손실과 정확도 계산\n",
    "test_loss = running_loss / sample_size\n",
    "test_acc = corrects.double() / sample_size\n",
    "\n",
    "print(f\"Total Test Loss: {test_loss}, Total Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "드롬아웃 정규화 과정 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms, models\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, default_collate\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='Training', transform=None):\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.transform = transform\n",
    "        self.labels = {'정상': 0, '균핵병': 1, '노균병': 2}\n",
    "        self.data = []\n",
    "        self._load_dataset()\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        for label_name, label in self.labels.items():\n",
    "            path = os.path.join(self.root_dir, '원천데이터', '05.상추', f'05.상추_{label}.{label_name}')\n",
    "            images = os.listdir(path)\n",
    "            for image in images:\n",
    "                self.data.append((os.path.join(path, image), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x[0] is not None, batch))\n",
    "    return default_collate(batch)\n",
    "\n",
    "transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "root_dir = '/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/modeldata'\n",
    "train_dataset = CustomDataset(root_dir=root_dir, split='Training', transform=transform)\n",
    "val_dataset = CustomDataset(root_dir=root_dir, split='Validation', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=my_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=my_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Epoch: 1/10, Phase: train, Loss: 0.42168913591206464, ACC: 0.847167325428195\n",
      "Epoch: 1/10, Phase: val, Loss: 0.1720637880645676, ACC: 0.9512195121951219\n",
      "Model saved\n",
      "================\n",
      "Epoch: 2/10, Phase: train, Loss: 0.12582179702995086, ACC: 0.9581686429512516\n",
      "Epoch: 2/10, Phase: val, Loss: 0.14616462485678908, ACC: 0.9490022172949002\n",
      "Model saved\n",
      "================\n",
      "Epoch: 3/10, Phase: train, Loss: 0.07149691717534747, ACC: 0.9782608695652174\n",
      "Epoch: 3/10, Phase: val, Loss: 0.10809867431362162, ACC: 0.9578713968957872\n",
      "Model saved\n",
      "================\n",
      "Epoch: 4/10, Phase: train, Loss: 0.04974500677880876, ACC: 0.9855072463768116\n",
      "Epoch: 4/10, Phase: val, Loss: 0.12119451209390639, ACC: 0.9578713968957872\n",
      "================\n",
      "Epoch: 5/10, Phase: train, Loss: 0.039559953635600206, ACC: 0.991106719367589\n",
      "Epoch: 5/10, Phase: val, Loss: 0.15483482419915845, ACC: 0.9445676274944568\n",
      "================\n",
      "Epoch: 6/10, Phase: train, Loss: 0.021660008480924527, ACC: 0.994729907773386\n",
      "Epoch: 6/10, Phase: val, Loss: 0.16063757690236058, ACC: 0.9445676274944568\n",
      "================\n",
      "Epoch: 7/10, Phase: train, Loss: 0.022474049600344322, ACC: 0.9940711462450593\n",
      "Epoch: 7/10, Phase: val, Loss: 0.13908832540509483, ACC: 0.9556541019955654\n",
      "================\n",
      "Epoch: 8/10, Phase: train, Loss: 0.018556005350968706, ACC: 0.9937417654808959\n",
      "Epoch: 8/10, Phase: val, Loss: 0.1279816120375617, ACC: 0.9578713968957872\n",
      "================\n",
      "Epoch: 9/10, Phase: train, Loss: 0.014140312696564133, ACC: 0.994729907773386\n",
      "Epoch: 9/10, Phase: val, Loss: 0.1634247722000941, ACC: 0.9445676274944568\n",
      "================\n",
      "Epoch: 10/10, Phase: train, Loss: 0.015337392852680907, ACC: 0.9944005270092227\n",
      "Epoch: 10/10, Phase: val, Loss: 0.1634905458099628, ACC: 0.9534368070953437\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# 모델 수정: 마지막 fc 레이어에 드롭아웃 추가\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),  # 50% 드롭아웃 추가\n",
    "    nn.Linear(num_ftrs, 3)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "best_cost = 1e+10\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"================\")\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        corrects = 0\n",
    "        sample_size = 0\n",
    "\n",
    "        dataloader = train_loader if phase == 'train' else val_loader\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "            sample_size += images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / sample_size\n",
    "        epoch_acc = corrects.double() / sample_size\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Phase: {phase}, Loss: {epoch_loss}, ACC: {epoch_acc}\")\n",
    "\n",
    "        if phase == 'val' and epoch_loss < best_cost:\n",
    "            print(\"Model saved\")\n",
    "            best_cost = epoch_loss\n",
    "            torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지를 불러오고 전처리하기 위한 transform 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((254, 254)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # 이미지 불러오기 및 변환\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    # 모델로 예측\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # 예측된 라벨 반환\n",
    "    return preds.item()\n",
    "\n",
    "# 모델 가중치 불러오기 (앞서 저장한 'model.pt')\n",
    "model.load_state_dict(torch.load('model.pt', map_location=device))\n",
    "\n",
    "# 예측할 이미지의 경로 설정\n",
    "image_path = '/Users/leeyeonju/Desktop/smart-plant-ai/이연주 서명.png'\n",
    "\n",
    "# 이미지에 대한 예측 라벨 출력\n",
    "predicted_label = predict_image(image_path)\n",
    "print(f'Predicted label: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 모델 구조를 재정의\n",
    "def initialize_model():\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),  # 50% 드롭아웃 추가\n",
    "        nn.Linear(num_ftrs, 3)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 이미지를 불러오고 전처리하기 위한 transform 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((254, 254)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 모델 로드\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = initialize_model()  # 모델 구조 초기화\n",
    "model.load_state_dict(torch.load('model.pt', map_location=device))  # 학습된 가중치 로드\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # 이미지 불러오기 및 변환\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원 추가\n",
    "\n",
    "    # 모델로 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # 예측된 라벨 반환\n",
    "    return preds.item()\n",
    "\n",
    "# 예시 사용\n",
    "# 예측 결과 = predict_image('path_to_your_image.jpg')\n",
    "# print(\"Predicted label:\", 예측 결과)\n",
    "\n",
    "\n",
    "res = predict_image('/Users/leeyeonju/Desktop/smart-plant-ai/smart_plant_ai/realdata/Training/원천데이터/05.상추/05.상추_2.노균병/V006_77_1_10_05_03_12_1_0149e_20201209_14.jpeg')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.3694264888763428, Batch Accuracy: 0.875\n",
      "Batch Loss: 0.1767321527004242, Batch Accuracy: 0.9375\n",
      "Batch Loss: 0.1822088062763214, Batch Accuracy: 0.9375\n",
      "Batch Loss: 0.12000128626823425, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.07223469018936157, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.04182419180870056, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.05307520553469658, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.15647490322589874, Batch Accuracy: 0.9375\n",
      "Batch Loss: 0.12362276017665863, Batch Accuracy: 0.9375\n",
      "Batch Loss: 0.17788153886795044, Batch Accuracy: 0.875\n",
      "Batch Loss: 0.04220421984791756, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.1340942531824112, Batch Accuracy: 0.875\n",
      "Batch Loss: 0.1630210280418396, Batch Accuracy: 0.875\n",
      "Batch Loss: 0.05923359841108322, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.21102644503116608, Batch Accuracy: 0.9375\n",
      "Batch Loss: 0.04461194574832916, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.12695112824440002, Batch Accuracy: 0.9375\n",
      "Batch Loss: 0.08250182867050171, Batch Accuracy: 0.9375\n",
      "Batch Loss: 0.10959117114543915, Batch Accuracy: 0.9375\n",
      "Batch Loss: 0.20227348804473877, Batch Accuracy: 0.9375\n",
      "Batch Loss: 0.4513767659664154, Batch Accuracy: 0.8125\n",
      "Batch Loss: 0.09472771733999252, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.26555198431015015, Batch Accuracy: 0.8125\n",
      "Batch Loss: 0.3000313937664032, Batch Accuracy: 0.75\n",
      "Batch Loss: 0.15022414922714233, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.14362089335918427, Batch Accuracy: 1.0\n",
      "Batch Loss: 0.4061908721923828, Batch Accuracy: 0.8125\n",
      "Batch Loss: 0.15269668400287628, Batch Accuracy: 0.9375\n",
      "Batch Loss: 0.4428335726261139, Batch Accuracy: 0.8\n",
      "Total Test Loss: 0.1708360724313811, Total Test Accuracy: 0.9279475982532751\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋과 데이터로더 설정\n",
    "test_dataset = CustomDataset(root_dir=root_dir, split='Test', transform=transform)  # 테스트 데이터셋 추가\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=my_collate_fn)  # 테스트 DataLoader 추가\n",
    "\n",
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model.eval()  # 모델을 평가 모드로 설정\n",
    "model.to(device)\n",
    "\n",
    "# 테스트 성능 평가\n",
    "running_loss = 0.0\n",
    "corrects = 0\n",
    "sample_size = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # forward\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "    batch_loss = loss.item() * images.size(0)\n",
    "    batch_corrects = torch.sum(preds == labels.data)\n",
    "    \n",
    "    running_loss += batch_loss\n",
    "    corrects += batch_corrects\n",
    "    sample_size += images.size(0)\n",
    "    \n",
    "    # 현재 배치에 대한 손실과 정확도 출력\n",
    "    print(f\"Batch Loss: {batch_loss / images.size(0)}, Batch Accuracy: {batch_corrects.double() / images.size(0)}\")\n",
    "\n",
    "# 전체 테스트 데이터셋에 대한 손실과 정확도 계산\n",
    "test_loss = running_loss / sample_size\n",
    "test_acc = corrects.double() / sample_size\n",
    "\n",
    "print(f\"Total Test Loss: {test_loss}, Total Test Accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
